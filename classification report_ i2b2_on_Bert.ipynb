{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "i2b2 on Bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM0y15eEPqHvwf+HfVcslrC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlsanf2000/HIR/blob/main/classification%20report_%20i2b2_on_Bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeIkCFMraKzm",
        "outputId": "6141367f-4fce-4320-8c6e-c4ec5cf8f772"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0diXmPhFbBmI",
        "outputId": "db3ea556-eb32-4d2d-bf89-fd201e5911aa"
      },
      "source": [
        "!pip install transformers\n",
        "import transformers"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ayl7u3C1bJqZ"
      },
      "source": [
        "from tqdm import tqdm, trange"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5W2QCqNbMT5"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qo83dM_ippaH"
      },
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/sep_df_Train.csv') #Set Dir\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/sep_df_Test.csv') #Set Dir"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "If0uSYf_RYl5",
        "outputId": "4e148b89-17e8-4790-e62d-76b17441956a"
      },
      "source": [
        "train_df['words']"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       ['Record', 'date:', '2083-10-18', 'CARDIOLOGY'...\n",
              "1       ['25', 'years.', 'He', 'is', 'not', 'married,'...\n",
              "2       ['tracing', 'is', 'Unchanged', 'Selected', 're...\n",
              "3       ['Record', 'date:', '2081-04-13', 'CARDIOLOGY'...\n",
              "4       ['history:', 'Unchanged', 'from', 'previous', ...\n",
              "                              ...                        \n",
              "2374    ['is', 'soft', 'and', 'non-tender,', 'no', 'sk...\n",
              "2375    ['due', 'to', 'cardiac', 'stents.', '2.', 'Upo...\n",
              "2376    ['Record', 'date:', '2074-02-22', 'Gregg,', 'L...\n",
              "2377    ['cut', 'back', 'because', 'his', 'wife', 'has...\n",
              "2378    ['I', 'think', 'he', 'found', 'this', 'soberin...\n",
              "Name: words, Length: 2379, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_6MefnabNQW"
      },
      "source": [
        "import ast\n",
        "train_df['words'] = train_df['words'].apply(ast.literal_eval)\n",
        "train_df['tags'] = train_df['tags'].apply(ast.literal_eval)\n",
        "test_df['words'] = test_df['words'].apply(ast.literal_eval)\n",
        "test_df['tags'] = test_df['tags'].apply(ast.literal_eval)\n",
        "\n",
        "train_words = train_df.words\n",
        "train_tags = train_df.tags\n",
        "\n",
        "test_words = test_df.words\n",
        "test_tags = test_df.tags"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcLMWynsRumn",
        "outputId": "b185dbd3-11ea-4b27-93ae-cf7961782b76"
      },
      "source": [
        "train_tags[0]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O',\n",
              " 'O',\n",
              " 'B-DATE',\n",
              " 'O',\n",
              " 'B-HOSPITAL',\n",
              " 'I-HOSPITAL',\n",
              " 'I-HOSPITAL',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-PATIENT',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-DATE',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-HOSPITAL',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-HOSPITAL',\n",
              " 'I-HOSPITAL',\n",
              " 'I-HOSPITAL',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-DATE',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-DATE',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-AGE',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-AGE',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-AGE',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-ORGANIZATION',\n",
              " 'I-ORGANIZATION',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4CtGYX6pmfQ"
      },
      "source": [
        "\n",
        "New_train_words , New_train_tags =  train_df['words'], train_df['tags']\n",
        "New_test_words , New_test_tags =  test_df['words'], test_df['tags']"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUSt8SUipyW9"
      },
      "source": [
        "class SentenceGetter(object):\n",
        "\n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
        "                                                           s[\"POS\"].values.tolist(),\n",
        "                                                           s[\"Tag\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "\n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-NE_ZmCp2ro"
      },
      "source": [
        "train_sentences = New_train_words\n",
        "test_sentences = New_test_words\n",
        "train_labels =  New_train_tags\n",
        "test_labels = New_test_tags"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "PYO3afGLp5T4",
        "outputId": "921148f8-b711-432d-8146-edc5efdc8101"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/dataframe.csv') #Set Dir\n",
        "\n",
        "data"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Word</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Record</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>date:</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2083-10-18</td>\n",
              "      <td>B-DATE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>CARDIOLOGY</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>WETZEL</td>\n",
              "      <td>B-HOSPITAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>815121</th>\n",
              "      <td>815121</td>\n",
              "      <td>Frank</td>\n",
              "      <td>B-DOCTOR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>815122</th>\n",
              "      <td>815122</td>\n",
              "      <td>T.</td>\n",
              "      <td>I-DOCTOR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>815123</th>\n",
              "      <td>815123</td>\n",
              "      <td>Xuan</td>\n",
              "      <td>I-DOCTOR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>815124</th>\n",
              "      <td>815124</td>\n",
              "      <td>,</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>815125</th>\n",
              "      <td>815125</td>\n",
              "      <td>M.D.</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>815126 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0        Word         Tag\n",
              "0                0      Record           O\n",
              "1                1       date:           O\n",
              "2                2  2083-10-18      B-DATE\n",
              "3                3  CARDIOLOGY           O\n",
              "4                4      WETZEL  B-HOSPITAL\n",
              "...            ...         ...         ...\n",
              "815121      815121       Frank    B-DOCTOR\n",
              "815122      815122          T.    I-DOCTOR\n",
              "815123      815123        Xuan    I-DOCTOR\n",
              "815124      815124           ,           O\n",
              "815125      815125        M.D.           O\n",
              "\n",
              "[815126 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVWeeDSyp70J"
      },
      "source": [
        "tag_values = list(set(data[\"Tag\"].values))\n",
        "tag_values.append(\"PAD\")\n",
        "tag2idx = {t: i for i, t in enumerate(tag_values)}"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BwLorGMSp9ee",
        "outputId": "c4f8ff20-fec0-4c80-f6d4-4541a68723b3"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertConfig\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "torch.__version__"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.8.0+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta6kRw-Kp_Mp"
      },
      "source": [
        "MAX_LEN = 256\n",
        "bs = 32"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DtOTiETqA7X"
      },
      "source": [
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RsCOuTAnqCSo",
        "outputId": "40254d09-ac24-4281-f606-f7c57e1a7d9a"
      },
      "source": [
        "torch.cuda.get_device_name(0)\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD0jCaNnqDnf"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=False)\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-s8f7tUqE36"
      },
      "source": [
        "def tokenize_and_preserve_labels(sentence, text_labels):\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    for word, label in zip(sentence, text_labels):\n",
        "\n",
        "        # Tokenize the word and count # of subwords the word is broken into\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        # Add the tokenized word to the final tokenized word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        # Add the same label to the new list of labels `n_subwords` times\n",
        "        labels.extend([label] * n_subwords)\n",
        "\n",
        "    return tokenized_sentence, labels"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gq7G6GiaqG-i"
      },
      "source": [
        "\n",
        "train_tokenized_texts_and_labels = [\n",
        "    tokenize_and_preserve_labels(sent, labs)\n",
        "    for sent, labs in zip(train_sentences, train_labels)\n",
        "]\n",
        "\n",
        "test_tokenized_texts_and_labels = [\n",
        "    tokenize_and_preserve_labels(sent, labs)\n",
        "    for sent, labs in zip(test_sentences, test_labels)\n",
        "]"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tId2OPUqInw"
      },
      "source": [
        "train_tokenized_texts = [token_label_pair[0] for token_label_pair in train_tokenized_texts_and_labels]\n",
        "train_labels = [token_label_pair[1] for token_label_pair in train_tokenized_texts_and_labels]\n",
        "\n",
        "test_tokenize_texts = [token_label_pair[0] for token_label_pair in test_tokenized_texts_and_labels]\n",
        "test_labels = [token_label_pair[1] for token_label_pair in test_tokenized_texts_and_labels]"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbBk__lMqLFY",
        "outputId": "3518d468-9885-4a33-9f60-c63b24a822b9"
      },
      "source": [
        "test_tokenize_texts[0][:10], test_labels[0][:10]\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['[UNK]', 'date', ':', '206', '##8', '-', '03', '-', '31', '[UNK]'],\n",
              " ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-DATE',\n",
              "  'B-DATE',\n",
              "  'B-DATE',\n",
              "  'B-DATE',\n",
              "  'B-DATE',\n",
              "  'B-DATE',\n",
              "  'B-HOSPITAL'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXYq0IqWqUod"
      },
      "source": [
        "\n",
        "train_input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in train_tokenized_texts],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n",
        "                          truncating=\"post\", padding=\"post\")\n",
        "\n",
        "test_input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in test_tokenize_texts],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n",
        "                          truncating=\"post\", padding=\"post\")"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6by6BN-BqWOM"
      },
      "source": [
        "train_tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in train_labels],\n",
        "                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")\n",
        "\n",
        "test_tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in test_labels],\n",
        "                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4xwMJe1qYQz"
      },
      "source": [
        "train_attention_masks = [[float(i != 0.0) for i in ii] for ii in train_input_ids]\n",
        "test_attention_masks = [[float(i != 0.0) for i in ii] for ii in test_input_ids]"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wyxy-snqaNZ"
      },
      "source": [
        "tr_inputs, val_inputs, tr_tags, val_tags = train_input_ids, test_input_ids, train_tags, test_tags\n",
        "\n",
        "tr_masks, val_masks = train_attention_masks, test_attention_masks"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YrGpDz9r3yl"
      },
      "source": [
        "tr_inputs = torch.tensor(tr_inputs)\n",
        "val_inputs = torch.tensor(val_inputs)\n",
        "tr_tags = torch.tensor(tr_tags)\n",
        "val_tags = torch.tensor(val_tags)\n",
        "tr_masks = torch.tensor(tr_masks)\n",
        "val_masks = torch.tensor(val_masks)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UmGbChNr5Wj"
      },
      "source": [
        "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
        "\n",
        "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
        "valid_sampler = SequentialSampler(valid_data)\n",
        "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oK9Wd749r62r",
        "outputId": "f2057e34-6182-4efe-b669-5e269d12447a"
      },
      "source": [
        "\n",
        "import transformers\n",
        "from transformers import BertForTokenClassification, AdamW\n",
        "\n",
        "transformers.__version__"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'4.4.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsBNIS7or8iW",
        "outputId": "ceb16be8-bfbe-4b9e-b3b3-b4ed86512549"
      },
      "source": [
        "\n",
        "model = BertForTokenClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=len(tag2idx),\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False\n",
        ")"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc7prJEqsIky"
      },
      "source": [
        "model.cuda();\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJxQOIMQshVq"
      },
      "source": [
        "input_size = len(train_data)\n",
        "num_layers = 3"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7PwmnFdX7fF"
      },
      "source": [
        "\n",
        "FULL_FINETUNING = True\n",
        "if FULL_FINETUNING:\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "else:\n",
        "    param_optimizer = list(model.classifier.named_parameters())\n",
        "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "\n",
        "optimizer = AdamW(\n",
        "    optimizer_grouped_parameters,\n",
        "    lr=3e-5,\n",
        "    eps=1e-8\n",
        ")"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiwO7_bYZLWX"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 5\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSeZF_IrZPO5",
        "outputId": "e726b201-838e-489c-bed9-f784ca8e620f"
      },
      "source": [
        "\n",
        "!pip install seqeval==0.0.17\n",
        "from seqeval.metrics import f1_score, accuracy_score,precision_score,recall_score"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: seqeval==0.0.17 in /usr/local/lib/python3.7/dist-packages (0.0.17)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval==0.0.17) (1.19.5)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from seqeval==0.0.17) (2.4.3)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras>=2.2.4->seqeval==0.0.17) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras>=2.2.4->seqeval==0.0.17) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras>=2.2.4->seqeval==0.0.17) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->Keras>=2.2.4->seqeval==0.0.17) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8F9J0oFZRPc",
        "outputId": "e7756bf4-aee2-47d0-872f-a8cddfb147ae"
      },
      "source": [
        "## 시간 측정 \n",
        "\n",
        "import time\n",
        "start = time.time()\n",
        "\n",
        "\n",
        "## Store the average loss after each epoch so we can plot them.\n",
        "loss_values, validation_loss_values = [], []\n",
        "\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    # Put the model into training mode.\n",
        "    model.train()\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Training loop\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # add batch to gpu\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        # Always clear any previously calculated gradients before performing a backward pass.\n",
        "        model.zero_grad()\n",
        "        # forward pass\n",
        "        # This will return the loss (rather than the model output)\n",
        "        # because we have provided the `labels`.\n",
        "        outputs = model(b_input_ids, token_type_ids=None,\n",
        "                        attention_mask=b_input_mask, labels=b_labels)\n",
        "        # get the loss\n",
        "        loss = outputs[0]\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "        # track train loss\n",
        "        total_loss += loss.item()\n",
        "        # Clip the norm of the gradient\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    print(\"Average train loss: {}\".format(avg_train_loss))\n",
        "\n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "    # Put the model into evaluation mode\n",
        "    model.eval()\n",
        "    # Reset the validation loss for this epoch.\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    predictions , true_labels = [], []\n",
        "    for batch in valid_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Telling the model not to compute or store gradients,\n",
        "        # saving memory and speeding up validation\n",
        "        with torch.no_grad():\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have not provided labels.\n",
        "            outputs = model(b_input_ids, token_type_ids=None,\n",
        "                            attention_mask=b_input_mask, labels=b_labels)\n",
        "        # Move logits and labels to CPU\n",
        "        logits = outputs[1].detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        eval_loss += outputs[0].mean().item()\n",
        "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "        true_labels.extend(label_ids)\n",
        "\n",
        "    eval_loss = eval_loss / len(valid_dataloader)\n",
        "    validation_loss_values.append(eval_loss)\n",
        "    print(\"Validation loss: {}\".format(eval_loss))\n",
        "    pred_tags = [tag_values[p_i] for p, l in zip(predictions, true_labels)\n",
        "                                 for p_i, l_i in zip(p, l) if tag_values[l_i] != \"PAD\"]\n",
        "    valid_tags = [tag_values[l_i] for l in true_labels\n",
        "                                  for l_i in l if tag_values[l_i] != \"PAD\"]\n",
        "    print(\"Validation Accuracy: {}\".format(accuracy_score(pred_tags, valid_tags)))\n",
        "    print(\"Validation F1-Score: {}\".format(f1_score(pred_tags, valid_tags)))\n",
        "    print(\"Validation Recall : {}\".format(recall_score(pred_tags, valid_tags)))\n",
        "    print(\"Validation Precision : {}\".format(precision_score(pred_tags, valid_tags)))\n",
        "    print()\n",
        "## 시간 측정 \n",
        "print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average train loss: 0.3950967025756836\n",
            "Validation loss: 0.14473096560686827\n",
            "Validation Accuracy: 0.9674142930240491\n",
            "Validation F1-Score: 0.7474339401056959\n",
            "Validation Recall : 0.8345221860904227\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  20%|██        | 1/5 [02:15<09:02, 135.61s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Precision : 0.6768046280148028\n",
            "\n",
            "Average train loss: 0.12472909212112426\n",
            "Validation loss: 0.09672823905323942\n",
            "Validation Accuracy: 0.9767212462334414\n",
            "Validation F1-Score: 0.799523282540223\n",
            "Validation Recall : 0.8000340730014055\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  40%|████      | 2/5 [04:30<06:46, 135.54s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Precision : 0.7990131439023352\n",
            "\n",
            "Average train loss: 0.08795241634051006\n",
            "Validation loss: 0.07606092235073447\n",
            "Validation Accuracy: 0.9804991756211269\n",
            "Validation F1-Score: 0.8349103532948076\n",
            "Validation Recall : 0.8309876959379741\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  60%|██████    | 3/5 [06:46<04:30, 135.43s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Precision : 0.8388702199157769\n",
            "\n",
            "Average train loss: 0.07086311837037404\n",
            "Validation loss: 0.06664485414512455\n",
            "Validation Accuracy: 0.9831485587583149\n",
            "Validation F1-Score: 0.8534552413353178\n",
            "Validation Recall : 0.8532375324178394\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  80%|████████  | 4/5 [09:01<02:15, 135.40s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Precision : 0.8536730613807478\n",
            "\n",
            "Average train loss: 0.06285090918342272\n",
            "Validation loss: 0.06503498802582423\n",
            "Validation Accuracy: 0.9839132412303144\n",
            "Validation F1-Score: 0.8595129214080613\n",
            "Validation Recall : 0.8595677699310814\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 5/5 [11:16<00:00, 135.39s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Precision : 0.8594580798842997\n",
            "\n",
            "time : 676.9424488544464\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kABbaiaA0bm1",
        "outputId": "dfbd9af2-7347-4b23-aea6-fa180a423897"
      },
      "source": [
        "# Reset the validation loss for this epoch.\n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "predictions , true_labels = [], []\n",
        "for batch in valid_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    # Telling the model not to compute or store gradients,\n",
        "    # saving memory and speeding up validation\n",
        "    with torch.no_grad():\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        # This will return the logits rather than the loss because we have not provided labels.\n",
        "        outputs = model(b_input_ids, token_type_ids=None,\n",
        "                        attention_mask=b_input_mask, labels=b_labels)\n",
        "    # Move logits and labels to CPU\n",
        "    logits = outputs[1].detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Calculate the accuracy for this batch of test sentences.\n",
        "    eval_loss += outputs[0].mean().item()\n",
        "    predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "    true_labels.extend(label_ids)\n",
        "\n",
        "eval_loss = eval_loss / len(valid_dataloader)\n",
        "validation_loss_values.append(eval_loss)\n",
        "print(\"Validation loss: {}\".format(eval_loss))\n",
        "pred_tags = [tag_values[p_i] for p, l in zip(predictions, true_labels)\n",
        "                              for p_i, l_i in zip(p, l) if tag_values[l_i] != \"PAD\"]\n",
        "valid_tags = [tag_values[l_i] for l in true_labels\n",
        "                              for l_i in l if tag_values[l_i] != \"PAD\"]\n",
        "print(\"Validation Accuracy: {}\".format(accuracy_score(valid_tags,pred_tags)))\n",
        "print(\"Validation F1-Score: {}\".format(f1_score(valid_tags,pred_tags)))\n",
        "print()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.06503498802582423\n",
            "Validation Accuracy: 0.9839132412303144\n",
            "Validation F1-Score: 0.8595129214080613\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQ3lgTR90hvO",
        "outputId": "9d54c70c-232a-4f7d-cf1a-82031aa760e9"
      },
      "source": [
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "print(\"Validation Accuracy: {}\".format(accuracy_score(valid_tags,pred_tags)))\n",
        "print(\"precision_score: {}\".format(precision_score(valid_tags,pred_tags)))\n",
        "print(\"recall_score: {}\".format(recall_score(valid_tags,pred_tags)))\n",
        "print(\"Validation F1-Score: {}\".format(f1_score(valid_tags,pred_tags)))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9839132412303144\n",
            "precision_score: 0.8595677699310814\n",
            "recall_score: 0.8594580798842997\n",
            "Validation F1-Score: 0.8595129214080613\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPOCwVYrZgoi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59922a7c-653d-4a8f-c1bd-de8d6bdb0dd1"
      },
      "source": [
        "print(classification_report(pred_tags,valid_tags))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "          AGE       0.94      0.86      0.90       742\n",
            "         DATE       0.97      0.98      0.98     14536\n",
            "       DOCTOR       0.58      0.47      0.52      2074\n",
            "     HOSPITAL       0.34      0.34      0.34       755\n",
            "        IDNUM       0.92      0.86      0.89       702\n",
            "MEDICALRECORD       0.97      0.97      0.97      1957\n",
            "      PATIENT       0.43      0.45      0.44      1145\n",
            "        PHONE       0.89      0.76      0.82       837\n",
            "        STATE       0.62      0.93      0.74       111\n",
            "       STREET       0.24      0.18      0.21       226\n",
            "     USERNAME       0.00      0.00      0.00         3\n",
            "          ZIP       0.87      0.82      0.84       418\n",
            "\n",
            "    micro avg       0.86      0.86      0.86     23506\n",
            "    macro avg       0.65      0.63      0.64     23506\n",
            " weighted avg       0.88      0.86      0.87     23506\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
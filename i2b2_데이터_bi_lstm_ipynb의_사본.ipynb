{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "i2b2 데이터 bi-lstm.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bwGnyXOemBS",
        "outputId": "4e2ae10d-ceda-41e4-a518-3bfa2c6c9920"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "%matplotlib inline\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMArjDKwfCak"
      },
      "source": [
        "import ast\r\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/sep_df_Train.csv') #Set Dir\r\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/sep_df_Test.csv') #Set Dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjGAEAUVgWIb"
      },
      "source": [
        "train_df['words'] = train_df['words'].apply(ast.literal_eval)\r\n",
        "train_df['tags'] = train_df['tags'].apply(ast.literal_eval)\r\n",
        "test_df['words'] = test_df['words'].apply(ast.literal_eval)\r\n",
        "test_df['tags'] = test_df['tags'].apply(ast.literal_eval)\r\n",
        "words = train_df.words\r\n",
        "tags = train_df.tags"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Og1AV3Zxg9Nv",
        "outputId": "87eb43e7-ee71-43f2-aaec-fc397507b67e"
      },
      "source": [
        "print(train_df.words[0])\r\n",
        "words[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Record', 'date:', '2083-10-18', 'CARDIOLOGY', 'WETZEL', 'COUNTY', 'HOSPITAL', 'Reason', 'for', 'visit:', 'Mr', 'Qazi', 'returns', 'for', 'followup', 'of', 'his', 'coronary', 'disease.', 'Interval', 'History:', 'He', 'was', 'recently', 'transferred', 'in', 'January', 'to', 'the', 'WCH', 'after', 'presenting', 'to', 'the', 'Florida', 'Hospital', 'Orlando', 'with', 'a', 'non', 'ST', 'segment', 'elevation', 'MI', 'in', 'the', 'anterolateral', 'zone.', 'He', 'underwent', 'angioplasty', 'and', 'stenting', 'of', 'his', 'proximal', 'LAD', 'using', 'a', '2.5', 'x', '13', 'mm', 'Cypher', 'drug', 'eluting', 'stent.', 'He', 'has', 'no', 'symptoms', 'of', 'chest', 'pain', 'or', 'pressure,', 'no', 'palpitations', 'dyspnea', 'or', 'orthopnea.', 'He', 'has', 'gained', 'some', 'weight', 'and', 'needs', 'to', 'work', 'on', 'that.', 'Past', 'medical', 'history:', '1.', 'CAD:', '-Cath', '1/73', ':', '80%', 'prox', 'RCA', 'stenosis', 'w/', 'thrombus,', 'mod', 'D1', 'stenosis,', 'clear', 'Lcx.', 'LV', 'gram', 'EF', '69%,', 'normal', 'motion.', '-Cath', '9/81', ':', 'Critical', 'proximal', 'ramus', 'lesion.', 'RCA', 'with', 'proximal', '40%', 'lesion,', 'patent', 'RCA', 'stent.', 'Patent', 'left', 'main,', 'apical', 'LAD', 'with', '99%', 'lesion', 'with', 'L-L', 'collaterals.', 'Cfx', '35%', 'mid', 'lesion.', 'Normal', 'LVEDP,', 'no', 'AS.', 'LVf', '50-55%.', '-Also', 'with', 'h/o', 'RCA', 'stent,', 'unclear', 'where', 'procedure', 'was', 'done', 'and', 'patient', 'unable', 'to', 'recall', 'details.', '2.', 'HTN', '3.', 'Hyperlipidemia', 'Medications', '(Confirmed):', 'Ecotrin', '325', 'mg', 'po', 'daily', 'Lipitor', '80mg', 'po', 'daily', 'nitroglycerin', '0.4', 'mg', 'sl', 'every', '5', 'minutes', 'PRN', 'chest', 'pain', 'Plavix', '75mg', 'po', 'daily', 'Toprol', 'XL', '50', 'mg', 'mg', 'po', 'bid', 'Tricor', '48mg', 'po', 'daily', 'Family', 'history:', 'Mother:', 'deceased', 'in', \"60's\", 'with', 'leukemia', 'Father:', 'extensive', 'CAD,', 'with', 'first', 'MI', 'in', \"50's\", '.', 'Had', 'MI', 'x7,', 'died', 'in', '70s', '.', 'Social', 'history:', 'He', 'runs', 'Mason', 'house', ',a', 'halfway', 'home.', 'He', 'has', 'h/o', 'drug/ETOH', 'abuse', 'but', 'denies', 'x']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Record',\n",
              " 'date:',\n",
              " '2083-10-18',\n",
              " 'CARDIOLOGY',\n",
              " 'WETZEL',\n",
              " 'COUNTY',\n",
              " 'HOSPITAL',\n",
              " 'Reason',\n",
              " 'for',\n",
              " 'visit:',\n",
              " 'Mr',\n",
              " 'Qazi',\n",
              " 'returns',\n",
              " 'for',\n",
              " 'followup',\n",
              " 'of',\n",
              " 'his',\n",
              " 'coronary',\n",
              " 'disease.',\n",
              " 'Interval',\n",
              " 'History:',\n",
              " 'He',\n",
              " 'was',\n",
              " 'recently',\n",
              " 'transferred',\n",
              " 'in',\n",
              " 'January',\n",
              " 'to',\n",
              " 'the',\n",
              " 'WCH',\n",
              " 'after',\n",
              " 'presenting',\n",
              " 'to',\n",
              " 'the',\n",
              " 'Florida',\n",
              " 'Hospital',\n",
              " 'Orlando',\n",
              " 'with',\n",
              " 'a',\n",
              " 'non',\n",
              " 'ST',\n",
              " 'segment',\n",
              " 'elevation',\n",
              " 'MI',\n",
              " 'in',\n",
              " 'the',\n",
              " 'anterolateral',\n",
              " 'zone.',\n",
              " 'He',\n",
              " 'underwent',\n",
              " 'angioplasty',\n",
              " 'and',\n",
              " 'stenting',\n",
              " 'of',\n",
              " 'his',\n",
              " 'proximal',\n",
              " 'LAD',\n",
              " 'using',\n",
              " 'a',\n",
              " '2.5',\n",
              " 'x',\n",
              " '13',\n",
              " 'mm',\n",
              " 'Cypher',\n",
              " 'drug',\n",
              " 'eluting',\n",
              " 'stent.',\n",
              " 'He',\n",
              " 'has',\n",
              " 'no',\n",
              " 'symptoms',\n",
              " 'of',\n",
              " 'chest',\n",
              " 'pain',\n",
              " 'or',\n",
              " 'pressure,',\n",
              " 'no',\n",
              " 'palpitations',\n",
              " 'dyspnea',\n",
              " 'or',\n",
              " 'orthopnea.',\n",
              " 'He',\n",
              " 'has',\n",
              " 'gained',\n",
              " 'some',\n",
              " 'weight',\n",
              " 'and',\n",
              " 'needs',\n",
              " 'to',\n",
              " 'work',\n",
              " 'on',\n",
              " 'that.',\n",
              " 'Past',\n",
              " 'medical',\n",
              " 'history:',\n",
              " '1.',\n",
              " 'CAD:',\n",
              " '-Cath',\n",
              " '1/73',\n",
              " ':',\n",
              " '80%',\n",
              " 'prox',\n",
              " 'RCA',\n",
              " 'stenosis',\n",
              " 'w/',\n",
              " 'thrombus,',\n",
              " 'mod',\n",
              " 'D1',\n",
              " 'stenosis,',\n",
              " 'clear',\n",
              " 'Lcx.',\n",
              " 'LV',\n",
              " 'gram',\n",
              " 'EF',\n",
              " '69%,',\n",
              " 'normal',\n",
              " 'motion.',\n",
              " '-Cath',\n",
              " '9/81',\n",
              " ':',\n",
              " 'Critical',\n",
              " 'proximal',\n",
              " 'ramus',\n",
              " 'lesion.',\n",
              " 'RCA',\n",
              " 'with',\n",
              " 'proximal',\n",
              " '40%',\n",
              " 'lesion,',\n",
              " 'patent',\n",
              " 'RCA',\n",
              " 'stent.',\n",
              " 'Patent',\n",
              " 'left',\n",
              " 'main,',\n",
              " 'apical',\n",
              " 'LAD',\n",
              " 'with',\n",
              " '99%',\n",
              " 'lesion',\n",
              " 'with',\n",
              " 'L-L',\n",
              " 'collaterals.',\n",
              " 'Cfx',\n",
              " '35%',\n",
              " 'mid',\n",
              " 'lesion.',\n",
              " 'Normal',\n",
              " 'LVEDP,',\n",
              " 'no',\n",
              " 'AS.',\n",
              " 'LVf',\n",
              " '50-55%.',\n",
              " '-Also',\n",
              " 'with',\n",
              " 'h/o',\n",
              " 'RCA',\n",
              " 'stent,',\n",
              " 'unclear',\n",
              " 'where',\n",
              " 'procedure',\n",
              " 'was',\n",
              " 'done',\n",
              " 'and',\n",
              " 'patient',\n",
              " 'unable',\n",
              " 'to',\n",
              " 'recall',\n",
              " 'details.',\n",
              " '2.',\n",
              " 'HTN',\n",
              " '3.',\n",
              " 'Hyperlipidemia',\n",
              " 'Medications',\n",
              " '(Confirmed):',\n",
              " 'Ecotrin',\n",
              " '325',\n",
              " 'mg',\n",
              " 'po',\n",
              " 'daily',\n",
              " 'Lipitor',\n",
              " '80mg',\n",
              " 'po',\n",
              " 'daily',\n",
              " 'nitroglycerin',\n",
              " '0.4',\n",
              " 'mg',\n",
              " 'sl',\n",
              " 'every',\n",
              " '5',\n",
              " 'minutes',\n",
              " 'PRN',\n",
              " 'chest',\n",
              " 'pain',\n",
              " 'Plavix',\n",
              " '75mg',\n",
              " 'po',\n",
              " 'daily',\n",
              " 'Toprol',\n",
              " 'XL',\n",
              " '50',\n",
              " 'mg',\n",
              " 'mg',\n",
              " 'po',\n",
              " 'bid',\n",
              " 'Tricor',\n",
              " '48mg',\n",
              " 'po',\n",
              " 'daily',\n",
              " 'Family',\n",
              " 'history:',\n",
              " 'Mother:',\n",
              " 'deceased',\n",
              " 'in',\n",
              " \"60's\",\n",
              " 'with',\n",
              " 'leukemia',\n",
              " 'Father:',\n",
              " 'extensive',\n",
              " 'CAD,',\n",
              " 'with',\n",
              " 'first',\n",
              " 'MI',\n",
              " 'in',\n",
              " \"50's\",\n",
              " '.',\n",
              " 'Had',\n",
              " 'MI',\n",
              " 'x7,',\n",
              " 'died',\n",
              " 'in',\n",
              " '70s',\n",
              " '.',\n",
              " 'Social',\n",
              " 'history:',\n",
              " 'He',\n",
              " 'runs',\n",
              " 'Mason',\n",
              " 'house',\n",
              " ',a',\n",
              " 'halfway',\n",
              " 'home.',\n",
              " 'He',\n",
              " 'has',\n",
              " 'h/o',\n",
              " 'drug/ETOH',\n",
              " 'abuse',\n",
              " 'but',\n",
              " 'denies',\n",
              " 'x']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ssbm4XNihPuj",
        "outputId": "d14c5b45-48c0-4bb4-d793-2ecd106722c2"
      },
      "source": [
        "tags.iloc[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [O, O, B-DATE, O, B-HOSPITAL, I-HOSPITAL, I-HO...\n",
              "1    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...\n",
              "2    [O, O, O, O, O, O, O, B-DATE, O, O, O, O, O, O...\n",
              "3    [O, O, B-DATE, O, B-HOSPITAL, I-HOSPITAL, I-HO...\n",
              "4    [O, O, O, O, O, O, O, O, O, O, O, O, O, B-CITY...\n",
              "Name: tags, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZRyZ6M6hZ0B",
        "outputId": "c07dace0-4394-4def-de81-a2d0bb7dcce2"
      },
      "source": [
        "print(tags[98])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-HOSPITAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-AGE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpbFnAzfhj-X"
      },
      "source": [
        "src_tokenizer = Tokenizer(oov_token='OOV') # 모든 단어를 사용하지만 인덱스 1에는 단어 'OOV'를 할당한다.\r\n",
        "src_tokenizer.fit_on_texts(words)\r\n",
        "tar_tokenizer = Tokenizer(lower=False) # 태깅 정보들은 내부적으로 대문자를 유지한채로 저장\r\n",
        "tar_tokenizer.fit_on_texts(tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBFuB_uNhrLi",
        "outputId": "b78f1d09-18bc-400c-baa9-90bf894baa54"
      },
      "source": [
        "vocab_size = len(src_tokenizer.word_index) + 1\r\n",
        "tag_size = len(tar_tokenizer.word_index) + 1\r\n",
        "print('단어 집합의 크기 : {}'.format(vocab_size))\r\n",
        "print('개체명 태깅 정보 집합의 크기 : {}'.format(tag_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기 : 44531\n",
            "개체명 태깅 정보 집합의 크기 : 44\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nIBb4L0hxFu"
      },
      "source": [
        "X_train = src_tokenizer.texts_to_sequences(words)\r\n",
        "y_train = tar_tokenizer.texts_to_sequences(tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eATq4ydqh12N",
        "outputId": "04990625-9867-448a-92de-052737421c9e"
      },
      "source": [
        "print(X_train[0])\r\n",
        "print(y_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[55, 50, 21645, 493, 11647, 1332, 116, 506, 12, 824, 853, 7351, 1178, 12, 1020, 4, 19, 124, 293, 844, 62, 11, 15, 317, 964, 7, 1000, 5, 3, 8293, 86, 521, 5, 3, 4777, 116, 11648, 8, 10, 1021, 422, 1707, 1655, 522, 7, 3, 4233, 11649, 11, 452, 1199, 2, 1656, 4, 19, 635, 352, 868, 10, 726, 78, 1363, 750, 2698, 515, 11650, 2192, 11, 16, 6, 153, 4, 40, 42, 21, 2823, 6, 1200, 569, 21, 2508, 11, 16, 2509, 83, 112, 2, 600, 5, 558, 14, 4027, 63, 67, 62, 117, 3050, 6595, 9640, 59, 2932, 2933, 735, 316, 129, 8294, 4028, 4234, 1901, 99, 7352, 1013, 2261, 551, 9641, 45, 2262, 6595, 8295, 59, 2934, 635, 4778, 2333, 735, 8, 635, 3051, 3052, 1113, 735, 2192, 1113, 43, 7353, 1364, 352, 8, 2067, 636, 8, 9642, 6596, 9643, 5108, 662, 2333, 45, 9644, 6, 7354, 9645, 9646, 11651, 8, 174, 735, 3625, 949, 707, 1022, 15, 318, 2, 26, 673, 5, 2935, 1482, 118, 250, 138, 403, 110, 3323, 2601, 311, 17, 20, 106, 194, 2263, 20, 106, 1023, 1657, 17, 1081, 751, 75, 816, 120, 40, 42, 528, 1849, 20, 106, 798, 663, 183, 17, 17, 20, 56, 5109, 9647, 20, 106, 100, 62, 3626, 3452, 7, 6030, 8, 5110, 3324, 1247, 637, 8, 464, 522, 7, 7355, 34, 30, 522, 9648, 507, 7, 6597, 34, 139, 62, 11, 5111, 6598, 2128, 11652, 8296, 965, 11, 16, 174, 9649, 2699, 37, 68, 78]\n",
            "[1, 1, 2, 1, 5, 8, 8, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 5, 1, 1, 1, 1, 5, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 1, 1, 1, 1, 1, 1, 7, 1, 1, 1, 1, 1, 22, 23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6o42W_uh34x"
      },
      "source": [
        "word_to_index = src_tokenizer.word_index\r\n",
        "index_to_word = src_tokenizer.index_word\r\n",
        "ner_to_index = tar_tokenizer.word_index\r\n",
        "index_to_ner = tar_tokenizer.index_word\r\n",
        "index_to_ner[0] = 'PAD'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjdkf969h7WC",
        "outputId": "d0e7c5c1-d1aa-4af5-93a6-3df40db9eaa7"
      },
      "source": [
        "print(index_to_ner)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 'O', 2: 'B-DATE', 3: 'B-DOCTOR', 4: 'I-DOCTOR', 5: 'B-HOSPITAL', 6: 'B-PATIENT', 7: 'B-AGE', 8: 'I-HOSPITAL', 9: 'I-DATE', 10: 'I-PATIENT', 11: 'B-MEDICALRECORD', 12: 'I-STREET', 13: 'B-CITY', 14: 'B-STATE', 15: 'B-PHONE', 16: 'B-USERNAME', 17: 'B-IDNUM', 18: 'B-PROFESSION', 19: 'B-STREET', 20: 'B-ZIP', 21: 'I-PROFESSION', 22: 'B-ORGANIZATION', 23: 'I-ORGANIZATION', 24: 'I-CITY', 25: 'B-COUNTRY', 26: 'I-IDNUM', 27: 'I-PHONE', 28: 'I-MEDICALRECORD', 29: 'I-AGE', 30: 'B-FAX', 31: 'I-COUNTRY', 32: 'I-LOCATION-OTHER', 33: 'B-DEVICE', 34: 'I-ZIP', 35: 'B-EMAIL', 36: 'B-LOCATION-OTHER', 37: 'I-URL', 38: 'I-STATE', 39: 'B-URL', 40: 'B-BIOID', 41: 'B-HEALTHPLAN', 42: 'I-HEALTHPLAN', 43: 'I-FAX', 0: 'PAD'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvsoLXsBh9px",
        "outputId": "928458f2-d894-4337-c55d-2a11af258772"
      },
      "source": [
        "decoded = []\r\n",
        "for index in X_train[0] : # 첫번째 샘플 안의 인덱스들에 대해서\r\n",
        "    decoded.append(index_to_word[index]) # 다시 단어로 변환\r\n",
        "\r\n",
        "print('기존의 문장 : {}'.format(words[0]))\r\n",
        "print('디코딩 문장 : {}'.format(decoded))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "기존의 문장 : ['Record', 'date:', '2083-10-18', 'CARDIOLOGY', 'WETZEL', 'COUNTY', 'HOSPITAL', 'Reason', 'for', 'visit:', 'Mr', 'Qazi', 'returns', 'for', 'followup', 'of', 'his', 'coronary', 'disease.', 'Interval', 'History:', 'He', 'was', 'recently', 'transferred', 'in', 'January', 'to', 'the', 'WCH', 'after', 'presenting', 'to', 'the', 'Florida', 'Hospital', 'Orlando', 'with', 'a', 'non', 'ST', 'segment', 'elevation', 'MI', 'in', 'the', 'anterolateral', 'zone.', 'He', 'underwent', 'angioplasty', 'and', 'stenting', 'of', 'his', 'proximal', 'LAD', 'using', 'a', '2.5', 'x', '13', 'mm', 'Cypher', 'drug', 'eluting', 'stent.', 'He', 'has', 'no', 'symptoms', 'of', 'chest', 'pain', 'or', 'pressure,', 'no', 'palpitations', 'dyspnea', 'or', 'orthopnea.', 'He', 'has', 'gained', 'some', 'weight', 'and', 'needs', 'to', 'work', 'on', 'that.', 'Past', 'medical', 'history:', '1.', 'CAD:', '-Cath', '1/73', ':', '80%', 'prox', 'RCA', 'stenosis', 'w/', 'thrombus,', 'mod', 'D1', 'stenosis,', 'clear', 'Lcx.', 'LV', 'gram', 'EF', '69%,', 'normal', 'motion.', '-Cath', '9/81', ':', 'Critical', 'proximal', 'ramus', 'lesion.', 'RCA', 'with', 'proximal', '40%', 'lesion,', 'patent', 'RCA', 'stent.', 'Patent', 'left', 'main,', 'apical', 'LAD', 'with', '99%', 'lesion', 'with', 'L-L', 'collaterals.', 'Cfx', '35%', 'mid', 'lesion.', 'Normal', 'LVEDP,', 'no', 'AS.', 'LVf', '50-55%.', '-Also', 'with', 'h/o', 'RCA', 'stent,', 'unclear', 'where', 'procedure', 'was', 'done', 'and', 'patient', 'unable', 'to', 'recall', 'details.', '2.', 'HTN', '3.', 'Hyperlipidemia', 'Medications', '(Confirmed):', 'Ecotrin', '325', 'mg', 'po', 'daily', 'Lipitor', '80mg', 'po', 'daily', 'nitroglycerin', '0.4', 'mg', 'sl', 'every', '5', 'minutes', 'PRN', 'chest', 'pain', 'Plavix', '75mg', 'po', 'daily', 'Toprol', 'XL', '50', 'mg', 'mg', 'po', 'bid', 'Tricor', '48mg', 'po', 'daily', 'Family', 'history:', 'Mother:', 'deceased', 'in', \"60's\", 'with', 'leukemia', 'Father:', 'extensive', 'CAD,', 'with', 'first', 'MI', 'in', \"50's\", '.', 'Had', 'MI', 'x7,', 'died', 'in', '70s', '.', 'Social', 'history:', 'He', 'runs', 'Mason', 'house', ',a', 'halfway', 'home.', 'He', 'has', 'h/o', 'drug/ETOH', 'abuse', 'but', 'denies', 'x']\n",
            "디코딩 문장 : ['record', 'date:', '2083-10-18', 'cardiology', 'wetzel', 'county', 'hospital', 'reason', 'for', 'visit:', 'mr', 'qazi', 'returns', 'for', 'followup', 'of', 'his', 'coronary', 'disease.', 'interval', 'history:', 'he', 'was', 'recently', 'transferred', 'in', 'january', 'to', 'the', 'wch', 'after', 'presenting', 'to', 'the', 'florida', 'hospital', 'orlando', 'with', 'a', 'non', 'st', 'segment', 'elevation', 'mi', 'in', 'the', 'anterolateral', 'zone.', 'he', 'underwent', 'angioplasty', 'and', 'stenting', 'of', 'his', 'proximal', 'lad', 'using', 'a', '2.5', 'x', '13', 'mm', 'cypher', 'drug', 'eluting', 'stent.', 'he', 'has', 'no', 'symptoms', 'of', 'chest', 'pain', 'or', 'pressure,', 'no', 'palpitations', 'dyspnea', 'or', 'orthopnea.', 'he', 'has', 'gained', 'some', 'weight', 'and', 'needs', 'to', 'work', 'on', 'that.', 'past', 'medical', 'history:', '1.', 'cad:', '-cath', '1/73', ':', '80%', 'prox', 'rca', 'stenosis', 'w/', 'thrombus,', 'mod', 'd1', 'stenosis,', 'clear', 'lcx.', 'lv', 'gram', 'ef', '69%,', 'normal', 'motion.', '-cath', '9/81', ':', 'critical', 'proximal', 'ramus', 'lesion.', 'rca', 'with', 'proximal', '40%', 'lesion,', 'patent', 'rca', 'stent.', 'patent', 'left', 'main,', 'apical', 'lad', 'with', '99%', 'lesion', 'with', 'l-l', 'collaterals.', 'cfx', '35%', 'mid', 'lesion.', 'normal', 'lvedp,', 'no', 'as.', 'lvf', '50-55%.', '-also', 'with', 'h/o', 'rca', 'stent,', 'unclear', 'where', 'procedure', 'was', 'done', 'and', 'patient', 'unable', 'to', 'recall', 'details.', '2.', 'htn', '3.', 'hyperlipidemia', 'medications', '(confirmed):', 'ecotrin', '325', 'mg', 'po', 'daily', 'lipitor', '80mg', 'po', 'daily', 'nitroglycerin', '0.4', 'mg', 'sl', 'every', '5', 'minutes', 'prn', 'chest', 'pain', 'plavix', '75mg', 'po', 'daily', 'toprol', 'xl', '50', 'mg', 'mg', 'po', 'bid', 'tricor', '48mg', 'po', 'daily', 'family', 'history:', 'mother:', 'deceased', 'in', \"60's\", 'with', 'leukemia', 'father:', 'extensive', 'cad,', 'with', 'first', 'mi', 'in', \"50's\", '.', 'had', 'mi', 'x7,', 'died', 'in', '70s', '.', 'social', 'history:', 'he', 'runs', 'mason', 'house', ',a', 'halfway', 'home.', 'he', 'has', 'h/o', 'drug/etoh', 'abuse', 'but', 'denies', 'x']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD338M-xiEbC"
      },
      "source": [
        "max_len = 250\r\n",
        "# 모든 샘플들의 길이를 맞출 때 뒤의 공간에 숫자 0으로 채움.\r\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=max_len)\r\n",
        "y_train = pad_sequences(y_train, padding='post', maxlen=max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v0LqoTViKvc"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=.2, random_state=777)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r03zukEJiM0v"
      },
      "source": [
        "y_train = to_categorical(y_train, num_classes=tag_size)\r\n",
        "y_test = to_categorical(y_test, num_classes=tag_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMX3AV5CiOnZ",
        "outputId": "5c703dab-f12a-4349-ca29-d8e9687198d4"
      },
      "source": [
        "print('훈련 샘플 문장의 크기 : {}'.format(X_train.shape))\r\n",
        "print('훈련 샘플 레이블의 크기 : {}'.format(y_train.shape))\r\n",
        "print('테스트 샘플 문장의 크기 : {}'.format(X_test.shape))\r\n",
        "print('테스트 샘플 레이블의 크기 : {}'.format(y_test.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련 샘플 문장의 크기 : (1903, 250)\n",
            "훈련 샘플 레이블의 크기 : (1903, 250, 44)\n",
            "테스트 샘플 문장의 크기 : (476, 250)\n",
            "테스트 샘플 레이블의 크기 : (476, 250, 44)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kr24s2-ruwkl",
        "outputId": "e7e4c640-6011-4554-8cb5-7085392db1dd"
      },
      "source": [
        "pip install seqeval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\r\u001b[K     |███████▌                        | 10kB 25.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 31.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30kB 22.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40kB 21.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.0.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp36-none-any.whl size=16171 sha256=2560ca513f91db9d2b525f2643e1c5e5a19bf28b5e3f12847d9282714c1805a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQMTfrAxur49"
      },
      "source": [
        "from seqeval.metrics import f1_score, classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvJcOm9IiR-N"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF6q75mQiX_p"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Embedding(vocab_size, 128, input_length=max_len, mask_zero=True))\r\n",
        "model.add(Bidirectional(LSTM(256, return_sequences=True)))\r\n",
        "model.add(TimeDistributed(Dense(tag_size, activation=('softmax'))))\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yQGriQmia1i",
        "outputId": "c343a593-1533-44ca-d966-c1953e510464"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=128, epochs=18,  validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/18\n",
            "14/14 [==============================] - 19s 479ms/step - loss: 2.3846 - accuracy: 0.7389 - val_loss: 0.3235 - val_accuracy: 0.9556\n",
            "Epoch 2/18\n",
            "14/14 [==============================] - 4s 302ms/step - loss: 0.2873 - accuracy: 0.9530 - val_loss: 0.2429 - val_accuracy: 0.9556\n",
            "Epoch 3/18\n",
            "14/14 [==============================] - 4s 229ms/step - loss: 0.3630 - accuracy: 0.9238 - val_loss: 0.3201 - val_accuracy: 0.9498\n",
            "Epoch 4/18\n",
            "14/14 [==============================] - 4s 297ms/step - loss: 0.3146 - accuracy: 0.9460 - val_loss: 0.2403 - val_accuracy: 0.9556\n",
            "Epoch 5/18\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.2335 - accuracy: 0.9541 - val_loss: 0.2214 - val_accuracy: 0.9556\n",
            "Epoch 6/18\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.2256 - accuracy: 0.9524 - val_loss: 0.2124 - val_accuracy: 0.9554\n",
            "Epoch 7/18\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.2091 - accuracy: 0.9529 - val_loss: 0.2023 - val_accuracy: 0.9554\n",
            "Epoch 8/18\n",
            "14/14 [==============================] - 4s 309ms/step - loss: 0.1888 - accuracy: 0.9534 - val_loss: 0.1902 - val_accuracy: 0.9554\n",
            "Epoch 9/18\n",
            "14/14 [==============================] - 4s 293ms/step - loss: 0.1702 - accuracy: 0.9541 - val_loss: 0.1765 - val_accuracy: 0.9567\n",
            "Epoch 10/18\n",
            "14/14 [==============================] - 4s 228ms/step - loss: 0.1530 - accuracy: 0.9556 - val_loss: 0.1649 - val_accuracy: 0.9574\n",
            "Epoch 11/18\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.1418 - accuracy: 0.9583 - val_loss: 0.1566 - val_accuracy: 0.9583\n",
            "Epoch 12/18\n",
            "14/14 [==============================] - 4s 295ms/step - loss: 0.1319 - accuracy: 0.9612 - val_loss: 0.1524 - val_accuracy: 0.9595\n",
            "Epoch 13/18\n",
            "14/14 [==============================] - 4s 291ms/step - loss: 0.1241 - accuracy: 0.9631 - val_loss: 0.1484 - val_accuracy: 0.9601\n",
            "Epoch 14/18\n",
            "14/14 [==============================] - 4s 297ms/step - loss: 0.1170 - accuracy: 0.9644 - val_loss: 0.1452 - val_accuracy: 0.9607\n",
            "Epoch 15/18\n",
            "14/14 [==============================] - 4s 298ms/step - loss: 0.1102 - accuracy: 0.9668 - val_loss: 0.1431 - val_accuracy: 0.9612\n",
            "Epoch 16/18\n",
            "14/14 [==============================] - 4s 299ms/step - loss: 0.1104 - accuracy: 0.9661 - val_loss: 0.1414 - val_accuracy: 0.9618\n",
            "Epoch 17/18\n",
            "14/14 [==============================] - 4s 294ms/step - loss: 0.1026 - accuracy: 0.9683 - val_loss: 0.1396 - val_accuracy: 0.9621\n",
            "Epoch 18/18\n",
            "14/14 [==============================] - 4s 296ms/step - loss: 0.0979 - accuracy: 0.9693 - val_loss: 0.1374 - val_accuracy: 0.9623\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3b98kz8tvJk",
        "outputId": "06f624c2-ed33-4a9d-b10b-b9fc86bd96c9"
      },
      "source": [
        "i=13 # 확인하고 싶은 테스트용 샘플의 인덱스.\r\n",
        "y_predicted = model.predict(np.array([X_test[i]])) # 입력한 테스트용 샘플에 대해서 예측 y를 리턴\r\n",
        "y_predicted = np.argmax(y_predicted, axis=-1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경함.\r\n",
        "true = np.argmax(y_test[i], -1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경함.\r\n",
        "\r\n",
        "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\r\n",
        "print(35 * \"-\")\r\n",
        "\r\n",
        "for w, t, pred in zip(X_test[i], true, y_predicted[0]):\r\n",
        "    if w != 0: # PAD값은 제외함.\r\n",
        "        print(\"{:17}: {:7} {}\".format(index_to_word[w], index_to_ner[t], index_to_ner[pred]))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어             |실제값  |예측값\n",
            "-----------------------------------\n",
            "-                : O       O\n",
            "i                : O       O\n",
            "have             : O       O\n",
            "discussed        : O       O\n",
            "with             : O       O\n",
            "mr.              : O       O\n",
            "quin             : B-PATIENT B-DATE\n",
            "that             : O       O\n",
            "we               : O       O\n",
            "are              : O       O\n",
            "likely           : O       O\n",
            "headed           : O       O\n",
            "toward           : O       O\n",
            "needing          : O       O\n",
            "a                : O       O\n",
            "surgical         : O       O\n",
            "urinary          : O       O\n",
            "diversion        : O       O\n",
            "with             : O       O\n",
            "an               : O       O\n",
            "ileal            : O       O\n",
            "conduit.         : O       O\n",
            "he               : O       O\n",
            "understands      : O       O\n",
            "this             : O       O\n",
            "and              : O       O\n",
            "is               : O       O\n",
            "still            : O       O\n",
            "considering      : O       O\n",
            "this.            : O       O\n",
            "we               : O       O\n",
            "will             : O       O\n",
            "continue         : O       O\n",
            "this             : O       O\n",
            "discussion       : O       O\n",
            "in               : O       O\n",
            "outpatient       : O       O\n",
            "follow           : O       O\n",
            "up.              : O       O\n",
            "quinton          : B-DOCTOR O\n",
            "h.               : I-DOCTOR O\n",
            "welch            : I-DOCTOR I-DOCTOR\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnQ_ul5Qh5dB"
      },
      "source": [
        "f1score = F1score(use_char=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RAQkVLCqYP4"
      },
      "source": [
        "y_predicted=model.predict([X_test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsE3qKD3oCVJ"
      },
      "source": [
        "pred_tags = f1score.sequences_to_tags(y_predicted)\r\n",
        "test_tags = f1score.sequences_to_tags(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQPykbK5oIUF",
        "outputId": "9a979bbc-9d48-423a-b7bd-f9a89d9a5bc9"
      },
      "source": [
        "print(\"f1-score : {:.1%}\".format(f1_score(test_tags,pred_tags)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1-score : 22.8%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "i2b2_ELMo_embedding의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOAgAv3TQ1Tdq/vTIZvuUmg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlsanf2000/HIR/blob/main/i2b2_ELMo_embedding_dim_error.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsLWLxs6plPx"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ekZiUrmuEXB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f207d8e-1310-4e08-b59c-2e67b4d078c9"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mdFBhQ6uLIl"
      },
      "source": [
        "# data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/bbc-text.csv')\r\n",
        "import ast\r\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/sep_df_Train.csv') #Set Dir\r\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/sep_df_Test.csv') #Set Dir"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzkJFDgMyyja"
      },
      "source": [
        "train_df['words'] = train_df['words'].apply(ast.literal_eval)\r\n",
        "train_df['tags'] = train_df['tags'].apply(ast.literal_eval)\r\n",
        "test_df['words'] = test_df['words'].apply(ast.literal_eval)\r\n",
        "test_df['tags'] = test_df['tags'].apply(ast.literal_eval)\r\n",
        "\r\n",
        "train_words = train_df.words\r\n",
        "train_tags = train_df.tags\r\n",
        "\r\n",
        "test_words = test_df.words\r\n",
        "test_tags = test_df.tags"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L7Lsc0Py0nM"
      },
      "source": [
        "words = list(train_words) + list(test_words)\r\n",
        "tags = list(train_tags) + list(test_tags)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mjW7gclna-T"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn5GOYCjXA5u"
      },
      "source": [
        "# from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "# from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "# from sklearn.model_selection import train_test_split\r\n",
        "# from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1dQXdCxWm6D"
      },
      "source": [
        "# # Tokenize\r\n",
        "# max_words = 70000\r\n",
        "# src_tokenizer = Tokenizer(num_words=max_words, oov_token='OOV')\r\n",
        "# src_tokenizer.fit_on_texts(words)\r\n",
        "\r\n",
        "# tar_tokenizer = Tokenizer()\r\n",
        "# tar_tokenizer.fit_on_texts(tags)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9obBn0-yYT4"
      },
      "source": [
        "# words"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVVpbDdKy_7O"
      },
      "source": [
        "# words = src_tokenizer.texts_to_sequences(words)\r\n",
        "# tags = src_tokenizer.texts_to_sequences(tags)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ao7Jva_2XI8w"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train, X_test, y_train, y_test = train_words, test_words, train_tags, test_tags"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNXgWvR3quHb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed4996aa-e9e4-4a15-c1f2-14b469c02d80"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [Record, date:, 2083-10-18, CARDIOLOGY, WETZEL...\n",
              "1       [25, years., He, is, not, married,, no, childr...\n",
              "2       [tracing, is, Unchanged, Selected, recent, lab...\n",
              "3       [Record, date:, 2081-04-13, CARDIOLOGY, ALGIER...\n",
              "4       [history:, Unchanged, from, previous, visits.,...\n",
              "                              ...                        \n",
              "2374    [is, soft, and, non-tender,, no, skin, rash., ...\n",
              "2375    [due, to, cardiac, stents., 2., Upon, review, ...\n",
              "2376    [Record, date:, 2074-02-22, Gregg,, Lloyd, 2-2...\n",
              "2377    [cut, back, because, his, wife, has, a, proble...\n",
              "2378    [I, think, he, found, this, sobering., 3., Gen...\n",
              "Name: words, Length: 2379, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yB-3NyCy4o9",
        "outputId": "d32dccee-5744-4bec-f26a-f7ce35e114e0"
      },
      "source": [
        "type(X_train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LZmRe6VWht_"
      },
      "source": [
        "# X_train = src_tokenizer.texts_to_sequences(X_train)\r\n",
        "# X_test = src_tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O670Pb9QrxjH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d1948f6-60af-42e0-b5f2-b55de372f3a3"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [Record, date:, 2083-10-18, CARDIOLOGY, WETZEL...\n",
              "1       [25, years., He, is, not, married,, no, childr...\n",
              "2       [tracing, is, Unchanged, Selected, recent, lab...\n",
              "3       [Record, date:, 2081-04-13, CARDIOLOGY, ALGIER...\n",
              "4       [history:, Unchanged, from, previous, visits.,...\n",
              "                              ...                        \n",
              "2374    [is, soft, and, non-tender,, no, skin, rash., ...\n",
              "2375    [due, to, cardiac, stents., 2., Upon, review, ...\n",
              "2376    [Record, date:, 2074-02-22, Gregg,, Lloyd, 2-2...\n",
              "2377    [cut, back, because, his, wife, has, a, proble...\n",
              "2378    [I, think, he, found, this, sobering., 3., Gen...\n",
              "Name: words, Length: 2379, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7hYzZ_JWiVQ"
      },
      "source": [
        "# y_train = tar_tokenizer.texts_to_sequences(y_train)\r\n",
        "# y_test = tar_tokenizer.texts_to_sequences(y_test)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg0pPTzRY6lJ"
      },
      "source": [
        "# vocab_size = max_words\r\n",
        "# tag_size = len(tar_tokenizer.word_index) + 1"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCb6w09hYziA"
      },
      "source": [
        "# from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "# max_len = 256\r\n",
        "# X_train = pad_sequences(X_train, padding='post', maxlen=max_len)\r\n",
        "# X_test = pad_sequences(X_test,padding='post', maxlen = max_len )\r\n",
        "# y_train = pad_sequences(y_train, padding = 'post', maxlen=max_len)\r\n",
        "# y_test = pad_sequences(y_test, padding = 'post', maxlen =max_len)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRZQqYGmr3dK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19fb7dda-0f4f-4ce5-98e8-8f98286ff30f"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [Record, date:, 2083-10-18, CARDIOLOGY, WETZEL...\n",
              "1       [25, years., He, is, not, married,, no, childr...\n",
              "2       [tracing, is, Unchanged, Selected, recent, lab...\n",
              "3       [Record, date:, 2081-04-13, CARDIOLOGY, ALGIER...\n",
              "4       [history:, Unchanged, from, previous, visits.,...\n",
              "                              ...                        \n",
              "2374    [is, soft, and, non-tender,, no, skin, rash., ...\n",
              "2375    [due, to, cardiac, stents., 2., Upon, review, ...\n",
              "2376    [Record, date:, 2074-02-22, Gregg,, Lloyd, 2-2...\n",
              "2377    [cut, back, because, his, wife, has, a, proble...\n",
              "2378    [I, think, he, found, this, sobering., 3., Gen...\n",
              "Name: words, Length: 2379, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJSDavfSY0VT"
      },
      "source": [
        "# y_train = to_categorical(y_train, num_classes=tag_size)\r\n",
        "# y_test = to_categorical(y_test, num_classes=tag_size)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn9m09raY8QR"
      },
      "source": [
        "# word_index = src_tokenizer.word_index"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmkdXk6xY29b"
      },
      "source": [
        "# vocab_size = len(src_tokenizer.word_index) + 1\r\n",
        "# tag_size = len(tar_tokenizer.word_index) + 1"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlvb4yfOwf2u"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import spacy\r\n",
        "from tqdm import tqdm\r\n",
        "import re\r\n",
        "import time\r\n",
        "import pickle\r\n",
        "pd.set_option('display.max_colwidth', 200)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s30sgHNw2UG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c6a0da3-99ab-419a-f29a-6cb00e93bb5b"
      },
      "source": [
        "!pip uninstall tensorflow tensorflow_hub tensorflowjs\r\n",
        "!pip install tensorflow==2.0.0a0 tensorflow_hub==0.5.0 tensorflowjs==1.2.6"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.4.1:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-2.4.1.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "y\n",
            "y\n",
            "  Successfully uninstalled tensorflow-2.4.1\n",
            "Uninstalling tensorflow-hub-0.11.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/make_image_classifier\n",
            "    /usr/local/bin/make_nearest_neighbour_index\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow_hub-0.11.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow_hub/*\n",
            "Proceed (y/n)?   Successfully uninstalled tensorflow-hub-0.11.0\n",
            "\u001b[33mWARNING: Skipping tensorflowjs as it is not installed.\u001b[0m\n",
            "Collecting tensorflow==2.0.0a0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/4e/402a4d7f21d03cd640b41376727a9ea2bac5a06d2556c04517878dad0c3d/tensorflow-2.0.0a0-cp37-cp37m-manylinux1_x86_64.whl (80.3MB)\n",
            "\u001b[K     |████████████████████████████████| 80.3MB 37kB/s \n",
            "\u001b[?25hCollecting tensorflow_hub==0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/be/f18c352d84382d9c795a0f37eaf16d42ace7d161fbb0ad20bdcd5e550015/tensorflow_hub-0.5.0-py2.py3-none-any.whl (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 12.9MB/s \n",
            "\u001b[?25hCollecting tensorflowjs==1.2.6\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/6a/b8da7692e9a289edbb83f4693ceb2c0be270ad30a5aee7438627e562ff95/tensorflowjs-1.2.6-py3-none-any.whl\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0a0) (0.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0a0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0a0) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0a0) (1.1.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0a0) (0.3.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0a0) (0.8.1)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 54.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0a0) (1.32.0)\n",
            "Collecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 47.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0a0) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0a0) (0.36.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0a0) (1.19.5)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0a0) (0.2.0)\n",
            "Collecting h5py==2.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/3f/724834613239667a92d3b8b6b8fdef1c93d6f57d008cacc46e6b9ebdc486/h5py-2.8.0-cp37-cp37m-manylinux1_x86_64.whl (2.8MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8MB 49.9MB/s \n",
            "\u001b[?25hCollecting keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 55.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0a0) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0a0) (1.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0a0) (53.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4->tensorflowjs==1.2.6) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4->tensorflowjs==1.2.6) (1.4.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0a0) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0a0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0a0) (3.4.0)\n",
            "\u001b[31mERROR: tensorflowjs 1.2.6 has requirement numpy==1.16.4, but you'll have numpy 1.19.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflowjs 1.2.6 has requirement six==1.11.0, but you'll have six 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflowjs 1.2.6 has requirement tensorflow==1.14.0, but you'll have tensorflow 2.0.0a0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, h5py, keras-applications, tensorflow, tensorflow-hub, keras, tensorflowjs\n",
            "  Found existing installation: h5py 2.10.0\n",
            "    Uninstalling h5py-2.10.0:\n",
            "      Successfully uninstalled h5py-2.10.0\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed h5py-2.8.0 keras-2.2.4 keras-applications-1.0.8 tb-nightly-1.14.0a20190301 tensorflow-2.0.0a0 tensorflow-hub-0.5.0 tensorflowjs-1.2.6 tf-estimator-nightly-1.14.0.dev2019030115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0KAo5_9xSnp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ff3d7aa-6e9e-4ade-ce67-dbcfaa7e3c84"
      },
      "source": [
        "!pip install tensorflow==1.15\r\n",
        "!pip install \"tensorflow_hub>=0.6.0\"\r\n",
        "!pip3 install tensorflow_text==1.15\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_hub as hub\r\n",
        "import numpy as np\r\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/2b/e3af15221da9ff323521565fa3324b0d7c7c5b1d7a8ca66984c8d59cb0ce/tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 50.0MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.19.5)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.36.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.12.4)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 49.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.32.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (53.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.8.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=157fcb26e4ad00fc4d579581bda52eb7a4d2101d83a4267c9f2f4cd95cab4c54\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflowjs 1.2.6 has requirement numpy==1.16.4, but you'll have numpy 1.19.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflowjs 1.2.6 has requirement six==1.11.0, but you'll have six 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflowjs 1.2.6 has requirement tensorflow==1.14.0, but you'll have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, gast, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorflow 2.0.0a0\n",
            "    Uninstalling tensorflow-2.0.0a0:\n",
            "      Successfully uninstalled tensorflow-2.0.0a0\n",
            "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n",
            "Collecting tensorflow_hub>=0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/1f/ca72fa5400954903aa6f3354142cd66374604384fb13429af9e41b12120d/tensorflow_hub-0.11.0-py2.py3-none-any.whl (107kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 15.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_hub>=0.6.0) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_hub>=0.6.0) (3.12.4)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow_hub>=0.6.0) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow_hub>=0.6.0) (53.0.0)\n",
            "\u001b[31mERROR: tensorflowjs 1.2.6 has requirement numpy==1.16.4, but you'll have numpy 1.19.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflowjs 1.2.6 has requirement six==1.11.0, but you'll have six 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflowjs 1.2.6 has requirement tensorflow==1.14.0, but you'll have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflowjs 1.2.6 has requirement tensorflow-hub==0.5.0, but you'll have tensorflow-hub 0.11.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-hub\n",
            "  Found existing installation: tensorflow-hub 0.5.0\n",
            "    Uninstalling tensorflow-hub-0.5.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.5.0\n",
            "Successfully installed tensorflow-hub-0.11.0\n",
            "Collecting tensorflow_text==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/93/cfa6d4532d9cb7707028d7d4fd505fa7aab9d6e08275322e516bf6de509d/tensorflow_text-1.15.0-cp37-cp37m-manylinux1_x86_64.whl (9.1MB)\n",
            "\u001b[K     |████████████████████████████████| 9.1MB 12.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<1.16,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text==1.15) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.32.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.19.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.12.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.36.2)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.15.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.2.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.3.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (53.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.3.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (2.8.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.7.4.3)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYqV9oi-24At",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "755ab0c2-8eb9-481c-e98c-f69f962874fb"
      },
      "source": [
        "!pip install tensorflow==1.15"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.15 in /usr/local/lib/python3.7/dist-packages (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.36.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.19.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.2)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.32.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.15) (53.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.8.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yw5pNamKybwI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f217cf9-a461-4ca8-932a-af4595fbe633"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_hub as hub\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "print(\"Version: \", tf.__version__)\r\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\r\n",
        "print(\"Hub version: \", hub.__version__)\r\n",
        "# print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Version:  1.15.0\n",
            "Eager mode:  False\n",
            "Hub version:  0.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N27e2FpNwjNK"
      },
      "source": [
        "import tensorflow_hub as hub\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "embed = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\r\n",
        "# elmo = hub.KerasLayer(\"https://tfhub.dev/google/elmo/2\", name=\"ELMO\")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYG8-YgO3pM_"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct1-W4zb4QsM"
      },
      "source": [
        "# le = preprocessing.LabelEncoder()\r\n",
        "# le.fit(y)\r\n",
        "\r\n",
        "# def encode(le, labels):\r\n",
        "#     enc = le.transform(labels)\r\n",
        "#     return keras.utils.to_categorical(enc)\r\n",
        "\r\n",
        "# def decode(le, one_hot):\r\n",
        "#     dec = np.argmax(one_hot, axis=1)\r\n",
        "#     return le.inverse_transform(dec)\r\n",
        "\r\n",
        "\r\n",
        "# x_enc = x\r\n",
        "# y_enc = encode(le, y)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9LCW5cL4TKa"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train, X_test, y_train, y_test = train_words, test_words, train_tags, test_tags"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvqFKPiL4WMB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e99c3b1d-2af8-4b85-8bcc-4ecdfa7a6350"
      },
      "source": [
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\r\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5ALlSEPdjon"
      },
      "source": [
        "# y_train = np.expand_dims(y_train, axis = 0)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOmhf9IOfaUr",
        "outputId": "9c98c162-d6ac-4f61-9433-d73e765f7780"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2379,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5J91EPQBfqTD",
        "outputId": "4e99b2c8-31cc-406b-f7ef-7f5f884a1bfd"
      },
      "source": [
        "type(y_train)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JqkiLav4mP3",
        "outputId": "e54c39ed-e7e4-4107-b19f-400dfa47477d"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [O, O, B-DATE, O, B-HOSPITAL, I-HOSPITAL, I-HOSPITAL, O, O, O, O, B-PATIENT, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-DATE, O, O, B-HOSPITAL, O, O, O, O, B-HOSPITAL, I-HOSPITAL, I-HOSPITAL, O, ...\n",
              "1       [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...\n",
              "2       [O, O, O, O, O, O, O, B-DATE, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-DOCTOR, I-DOCT...\n",
              "3       [O, O, B-DATE, O, B-HOSPITAL, I-HOSPITAL, I-HOSPITAL, B-DOCTOR, I-DOCTOR, O, O, O, B-HOSPITAL, I-HOSPITAL, I-HOSPITAL, O, O, O, B-DOCTOR, O, O, O, O, O, O, O, O, B-PATIENT, I-PATIENT, O, O, O, O, ...\n",
              "4       [O, O, O, O, O, O, O, O, O, O, O, O, O, B-CITY, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O...\n",
              "                                                                                                         ...                                                                                                   \n",
              "2374    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...\n",
              "2375    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...\n",
              "2376    [O, O, B-DATE, B-PATIENT, I-PATIENT, B-DATE, O, O, O, B-STREET, I-STREET, I-STREET, O, B-CITY, O, B-STATE, B-ZIP, O, O, O, O, B-AGE, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-HOSPITAL, O, O, B-D...\n",
              "2377    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...\n",
              "2378    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-DOCTOR, I-DOCTOR, I...\n",
              "Name: tags, Length: 2379, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACcLHXT54mJI"
      },
      "source": [
        "# y"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PtA7A3CfvCz"
      },
      "source": [
        "# for i"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIhVorrK4i8m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        },
        "outputId": "5fb4559a-ae5d-477d-cf9f-654b6aa95934"
      },
      "source": [
        "from keras.layers import Input, Lambda, Dense\r\n",
        "from keras.models import Model\r\n",
        "import keras.backend as K\r\n",
        "\r\n",
        "def ELMoEmbedding(x):\r\n",
        "    return embed(tf.squeeze(tf.cast(x, tf.string)), as_dict = True, signature = \"default\")[\"default\"]\r\n",
        "\r\n",
        "input_text = Input(shape=(1,), dtype=tf.string)\r\n",
        "embedding = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text)\r\n",
        "\r\n",
        "x = Bidirectional(LSTM(units=512, return_sequences=True, recurrent_dropout=0.2, dropout=0.2))(embedding)\r\n",
        "x_rnn = Bidirectional(LSTM(units=512, return_sequences=True, recurrent_dropout = 0.2, dropout=0.2))(x)\r\n",
        "x = add([x, x_rnn])\r\n",
        "out = TimeDistributed(Dense(tag_size, activation = \"softmax\"))(x)\r\n",
        "\r\n",
        "# dense = Dense(2379, activation='relu')(embedding)\r\n",
        "# pred = Dense(1, activation='softmax')(dense)\r\n",
        "\r\n",
        "# model = Model(inputs=[input_text], outputs=pred)\r\n",
        "model = Model(input_text, out)\r\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-d88c4526c841>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mELMoEmbedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurrent_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mx_rnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurrent_dropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_rnn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/wrappers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;31m# Applies the same workaround as in `RNN.__call__`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer bidirectional_1: expected ndim=3, found ndim=2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQB5ryjwWyOV"
      },
      "source": [
        "# from keras.utils import to_categorical\r\n",
        "\r\n",
        "# with tf.Session() as session:\r\n",
        "#     K.set_session(session)\r\n",
        "#     session.run(tf.global_variables_initializer())  \r\n",
        "#     session.run(tf.tables_initializer())\r\n",
        "#     y_train = to_categorical(y_train)\r\n",
        "#     history = model.fit(X_train, y_train, epochs=1, batch_size=16)\r\n",
        "#     model.save_weights('./elmo-model.h5')\r\n",
        "\r\n",
        "# with tf.Session() as session:\r\n",
        "#     K.set_session(session)\r\n",
        "#     session.run(tf.global_variables_initializer())\r\n",
        "#     session.run(tf.tables_initializer())\r\n",
        "#     model.load_weights('./elmo-model.h5')  \r\n",
        "#     predicts = model.predict(X_test, batch_size=16)\r\n",
        "\r\n",
        "# y_test = decode(le, y_test)\r\n",
        "# y_preds = decode(le, predicts)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDW8O28mMqC-"
      },
      "source": [
        "X_train.shape\r\n",
        "# type(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2IKsBcw2g7q"
      },
      "source": [
        "X_train = X_train.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHu4tlQK23ek"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Rk3MVwv27k2"
      },
      "source": [
        "type(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukDMtat88nm1"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVkuSnk7VYgG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4BAD_5TDTos"
      },
      "source": [
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs = 1, batch_size = 16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EGY9Had0KlZ"
      },
      "source": [
        "X_train = X_train.astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ifmln6h50jJx"
      },
      "source": [
        "y_train = y_train.astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5dz91Wp0MI3"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pigiFfGxFVCE"
      },
      "source": [
        "predicts = model.predict(X_test, batch_size=16)\r\n",
        "\r\n",
        "y_test = decode(le, y_test)\r\n",
        "y_preds = decode(le, predicts, axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSLFkOHeWD0C"
      },
      "source": [
        "# from sklearn import metrics\r\n",
        "\r\n",
        "# print(metrics.confusion_matrix(y_test, y_preds))\r\n",
        "\r\n",
        "# print(metrics.classification_report(y_test, y_preds))\r\n",
        "\r\n",
        "# from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "# print(\"Accuracy of ELMO is:\",accuracy_score(y_test,y_preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aK53tXtWsuj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}